{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 2",
      "language": "python",
      "name": "python2"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.13"
    },
    "colab": {
      "name": "AditiGopalan_Assignment3.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "D_5CPfxJxJmH"
      },
      "source": [
        "### Assignment 3\n",
        "\n",
        "This is Assignment 3. Deadline for submission is November, 16, 11pm EST. Please send your solutions in a gzipped archive to dmm2017@med.cornell.edu, with copy to chb4004@med.cornell.edu. No extensions will be granted. Your archive should contain this ipynb file with the code you wrote. However, if you are not comfortable with python, you can write in any other programming language, but provide instructions how to run/compile your code. Also, refer to the \"Output data\" section."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "gIP0m6gVxJmP"
      },
      "source": [
        "## De-Bruijn graph\n",
        "The goal of this project is to build a basic De-Bruijn graph assembler.\n",
        "Write a program that:\n",
        "1. Takes fastq-file as input\n",
        "2. Builds condensed De-Bruijn graph. Use k = 55.\n",
        "3. Counts average k-mer coverage for each edge. (Kmer coverage is a number of times we see kmer in reads. Average kmer edge coverage is an average of all its kmer coverages).\n",
        "4. Outputs result in a .dot file.  Each edge should have a label with it's length and average coverage.\n",
        "5. Convert dot file into image file (png, svg, or jpg format).\n",
        "6. Write TipClipping function that simplifies condensed De-Bruijn graph. Think about parameters and their values, so graph is properly simplified. Note, that after this procedure graph should remain condensed.\n",
        "7. Produce dot and image files for simplified graph.\n",
        "8. Measure running times of your solution for input files provided\n",
        "\n",
        "## Hints\n",
        "\n",
        "1. Add kmer and reverse-complement kmer to graph simultaneously, so your graph will be symmetric.\n",
        "\n",
        "## Input data\n",
        "\n",
        "You will be provided a three input fastq files of different sizes and reference genomes (so you could assess your results if needed).\n",
        "\n",
        "## Output data\n",
        "\n",
        "1. Short report on how you constructed graph, performed simplification, running times.\n",
        "2. Figures that show assembly graph structure\n",
        "\n",
        "## Grading\n",
        "\n",
        "1. Correctness - graphs are correctly constructed, simplified, coverage is correct (even if it done only for the smallest sample) - 40%\n",
        "2. Running time - 10% for each file (the largest file gives additional points). We don't set a hard time limit here, but your program should finish within minutes on your computer.\n",
        "3. Report quality - 20%\n",
        "4. Code quality - 20%\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "L4K_BDb9xJmR"
      },
      "source": [
        "from Bio import SeqIO\n",
        "from graphviz import Digraph\n",
        "import argparse\n",
        "import pydot\n",
        "import time\n",
        "start_time = time.time()\n",
        "\n",
        "class Vertex:\n",
        "\n",
        "    def __init__(self, seq):\n",
        "        self.seq = seq\n",
        "        self.vertex_coverage = 1\n",
        "        self.in_edges = {}\n",
        "        self.out_edges = {}\n",
        "\n",
        "    def increase_vertex_coverage(self):\n",
        "        self.vertex_coverage += 1\n",
        "\n",
        "class Edge:\n",
        "\n",
        "    def __init__(self, current_kmer, next_kmer):\n",
        "        self.seq = current_kmer + next_kmer[-1]\n",
        "        self.in_vertices = {}\n",
        "        self.out_vertices = {}\n",
        "\n",
        "\n",
        "        self.edge_coverage = 0\n",
        "\n",
        "    def increase_edge_coverage(self):\n",
        "        self.edge_coverage += 1\n",
        "\n",
        "    def calculation_edge_coverage(self, prev_vertex_cov, next_vertex_cov):\n",
        "        self.edge_coverage = (prev_vertex_cov + next_vertex_cov)/2\n",
        "\n",
        "    def merge_next(self, next):\n",
        "        self.seq += next.seq[k:]\n",
        "        self.edge_coverage = (self.edge_coverage * len(self.seq) + next.edge_coverage * len(next.seq)) / (len(self.seq) + len(next.seq))\n",
        "\n",
        "    def merge_prev(self, prev):\n",
        "        self.seq = prev.seq + self.seq[k:]\n",
        "        self.edge_coverage = (self.edge_coverage * len(self.seq) + prev.edge_coverage * len(prev.seq)) / (len(self.seq) + len(prev.seq))\n",
        "\n",
        "class Graph:\n",
        "\n",
        "    def __init__(self, k):\n",
        "        self.vertices = {}\n",
        "        self.k = k\n",
        "\n",
        "    def add_read(self, read):\n",
        "\n",
        "        if len(read) < self.k:\n",
        "            return\n",
        "\n",
        "        # first k-mer\n",
        "        kmer = read[:self.k]\n",
        "        if kmer in self.vertices:\n",
        "            self.vertices[kmer].increase_vertex_coverage()\n",
        "        else:\n",
        "            self.vertices[kmer] = Vertex(kmer)\n",
        "\n",
        "        # next k-mer iterations:\n",
        "        for i in range(1, len(read)-self.k+1, 1):\n",
        "            next_kmer = read[i:i+self.k]\n",
        "            if next_kmer in self.vertices:\n",
        "                self.vertices[next_kmer].increase_vertex_coverage()\n",
        "            else:\n",
        "                self.vertices[next_kmer] = Vertex(next_kmer)\n",
        "\n",
        "            # add new edge\n",
        "            new_edge = Edge(kmer, next_kmer)\n",
        "            # add vertices\n",
        "            self.vertices[next_kmer].in_edges[kmer] = [new_edge]\n",
        "            self.vertices[kmer].out_edges[next_kmer] = [new_edge]\n",
        "            kmer = next_kmer\n",
        "\n",
        "    def coverage_calculating(self):\n",
        "        for current_vertex in self.vertices.keys():\n",
        "            for next_vertex in self.vertices[current_vertex].out_edges.keys():\n",
        "                self.vertices[current_vertex].out_edges[next_vertex][0] \\\n",
        "                    .calculation_edge_coverage(self.vertices[current_vertex].vertex_coverage,\n",
        "                                               self.vertices[next_vertex].vertex_coverage)\n",
        "\n",
        "    def merge_vertices(self, vertex, prev, next):\n",
        "        self.vertices[prev].out_edges[next] = [Edge(prev, next)]\n",
        "        self.vertices[next].in_edges[prev] = [Edge(prev, next)]\n",
        "        self.vertices[prev].out_edges[next][0].merge_next(self.vertices[next].in_edges[prev][0])\n",
        "        self.vertices[next].in_edges[prev][0].merge_prev(self.vertices[prev].out_edges[next][0])\n",
        "\n",
        "        del self.vertices[vertex]\n",
        "        del self.vertices[prev].out_edges[vertex]\n",
        "        del self.vertices[next].in_edges[vertex]\n",
        "\n",
        "    def compress(self):\n",
        "        blacklist = []\n",
        "        for vertex in self.vertices.keys():\n",
        "            if (len(list(self.vertices[vertex].out_edges.keys()))) == 1 and (len(list(self.vertices[vertex].in_edges.keys())) == 1):\n",
        "                blacklist.append(vertex)\n",
        "        for vertex in blacklist:\n",
        "            if vertex in self.vertices.keys() and len(self.vertices) > 2:\n",
        "                prev, next = list(self.vertices[vertex].in_edges.keys())[0], list(self.vertices[vertex].out_edges.keys())[0]\n",
        "                self.merge_vertices(vertex, prev, next)\n",
        "\n",
        "    def cut(self):\n",
        "        baseline = 1.2\n",
        "        self.to_cut = [vertex for vertex in self.vertices.keys() if ((len(self.vertices[vertex].out_edges.keys()) == 0) and (len(self.vertices[vertex].in_edges.keys()) == 1))\n",
        "                       or ((len(self.vertices[vertex].out_edges.keys()) == 1) and (len(self.vertices[vertex].in_edges.keys()) == 0))\n",
        "                       or ((len(self.vertices[vertex].out_edges.keys()) == 0) and (len(self.vertices[vertex].in_edges.keys()) == 0))]\n",
        "        for vertex in self.to_cut:\n",
        "            if self.vertices[vertex].vertex_coverage <= baseline:\n",
        "                if len(self.vertices[vertex].out_edges.keys()) == 1:\n",
        "                    self.vertices[list(self.vertices[vertex].out_edges.keys())[0]].in_edges.pop(vertex)\n",
        "                if len(self.vertices[vertex].in_edges.keys()) == 1:\n",
        "                    self.vertices[list(self.vertices[vertex].in_edges.keys())[0]].out_edges.pop(vertex)\n",
        "\n",
        "                del self.vertices[vertex]\n",
        "\n",
        "    def graph_vis(self, result):\n",
        "\n",
        "\n",
        "        dot = Digraph(comment='Assemble')\n",
        "\n",
        "\n",
        "        if result == 'full':\n",
        "            for k, v in self.vertices.items():\n",
        "\n",
        "                dot.node(k, label=f'{k}')\n",
        "                for kk, vv in v.out_edges.items():\n",
        "                    dot.edge(k, kk, label=f'{vv[0].seq}')\n",
        "        else:\n",
        "            for k, v in self.vertices.items():\n",
        "\n",
        "                dot.node(k, label=k)\n",
        "                for kk, vv in v.out_edges.items():\n",
        "                    print(v.out_edges)\n",
        "                    dot.edge(k, kk, label=f'cov={vv[0].edge_coverage} len={len(vv[0].seq)}')\n",
        "\n",
        "        #print(dot.source)\n",
        "        dot.view()\n",
        "        dot.save()\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "\n",
        "    parser = argparse.ArgumentParser(description='''Graph Visualization''')\n",
        "    parser.add_argument('-i', '--input', help='Input fastq', type=str)\n",
        "    parser.add_argument('-k', '--kmer', help='k-mer length', default=55, type=int)\n",
        "    parser.add_argument('-t', '--type', help='full', default='full', type=str)\n",
        "    parser.add_argument('-c', help='Graph Compression', action='store_true')\n",
        "\n",
        "\n",
        "\n",
        "    args = parser.parse_args()\n",
        "\n",
        "    i, k, t, s = args.input, args.kmer, args.type, args.strand\n",
        "\n",
        "    my_graph = Graph(k)\n",
        "    if s == 'fw':\n",
        "        with open(i) as f:\n",
        "            for record in SeqIO.parse(f, 'fastq'):\n",
        "                my_graph.add_read(str(record.seq))\n",
        "    else:\n",
        "        with open(i) as f:\n",
        "            for record in SeqIO.parse(f, 'fastq'):\n",
        "                my_graph.add_read(str(record.reverse_complement().seq))\n",
        "\n",
        "    my_graph.coverage_calculating()\n",
        "\n",
        "    if args.c:\n",
        "        my_graph.compress()\n",
        "        my_graph.cut()\n",
        "\n",
        "    my_graph.graph_vis(result=t)\n",
        "    print(\"--- %s seconds ---\" % (time.time() - start_time))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UPnzirRNy0Sx"
      },
      "source": [
        "\n",
        "# Report\n",
        "\n",
        "**Code Organization**\n",
        "\n",
        "My code is divided into 3 classes:\n",
        "\n",
        "1.   Vertex: This has graph vertices which represent individual k-mers. It has coincident edges and coverage \n",
        "2.   Edge: This contains edge coverage calculated as: \n",
        "edge coverage = (weighted edge coverage)*(number of combined edges)/ total number of combined edges. The condensing and tip clipping functions are also included in this segment. \n",
        "3. Graph: This contains dunctions to calculate coverage and visualize the graphs.\n",
        "\n",
        "**Construction of the graph**\n",
        "\n",
        "1. Parse and read the fastq files that are substrings of the reference genome\n",
        "2. Each input string (kmer) of length k (here k = 55) was split it into overlapping substrings (kmers) of length k-1.  \n",
        "3. Draw a directed multigraph between the k-1mers. Each edge on this graph represents the overlap between the k-1mers or a kmer to obtain the de bruijn graph.\n",
        "\n",
        "\n",
        "**Condensing or simplification**\n",
        "\n",
        "It is possible to simplify the graphs without any loss of information. When a vertex has only one incoming arc and one outgoing arc and if the outgoing arc is the only incoming arc on the next node, I merged the two nodes (function compress).\n",
        "\n",
        "**Tip Clipping**\n",
        "\n",
        "I further simplified the graph by deleting 'tips' or nodes that are connected only on one end. I set a baseline value of 2*k where k = kmer length. Every tip that is shorter than 2*k is removed. I chose this baseline value because a) this is longer than any short read and it is unlikely that any short read will have that many errors b)For longer reads, this is the value of two adjacent errors. Any length longer than this will only represent a real sequence or one that looks extremely real. \n",
        "\n",
        "When there are no more tips to remove, I condensed the graph once again. \n",
        "\n",
        "**Runtime** \n",
        "\n",
        "I ran most of my code from the commandline. The run time for the files were:\n",
        "\n",
        "1k file:  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Uj7RhGvkQfw"
      },
      "source": [
        "python3 dbg2.py -i first1000.fastq -k 55 -t not -c\n",
        "--- 0.27452516555786133 seconds ---"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XbBMYEePkVX-"
      },
      "source": [
        "10k file:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NxhISXxbkQ0c"
      },
      "source": [
        "python3 dbg2.py -i first10000.fastq -k 55 -t not -c\n",
        "--- 4.460830926895142 seconds ---"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s9A2t9-uknpp"
      },
      "source": [
        "100k file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cH5iVFOdkRAK"
      },
      "source": [
        "python3 dbg2.py -i first10000.fastq -k 55 -t not -c\n",
        "--- 86.75118064880371 seconds ---"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6K5Bbyt9mTtu"
      },
      "source": [
        "**Improvements that can be made to the code**\n",
        "\n",
        "My outputs are attached in the folder. I do think that my output for the last file is not correct, however I did not have the time to fix this. This algorithm also doesn't remove redundant paths or paths that start and end at the same node. This is another thing that could be improved. I tried my best to code more elegantly this time by use of functions and classes as opposed too many nested lists, to make sure the code runs within minutes. I have learned to do this better with every assignment. "
      ]
    }
  ]
}